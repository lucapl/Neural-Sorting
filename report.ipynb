{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.metrics import AUC,Accuracy\n",
    "\n",
    "from src.tensors.metrics import UtilMetric,F1Score\n",
    "from src.tensors.losses import mean_regret\n",
    "from src.tensors.utils import train\n",
    "from src.tensors.models import create_ann_utadis_model,create_nn_model\n",
    "from src.viz import show_class_counts,visualize_data,show_combinations,show_stats,show_history,show_monotone_blocks,show_criteria_weights\n",
    "from src.utils import undersample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car evaluation\n",
    "\n",
    "#### Łukasz Andryszewski 151930"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used is the Car Evalutaion dataset which can be found [here](https://en.cs.uni-paderborn.de/is/research/research-projects/software/monotone-learning-datasets).\n",
    "\n",
    "It consists of six criterions and four classes. The criterions are:\n",
    "- price\n",
    "- price of the maintenance\n",
    "- number of doors\n",
    "- capacity \n",
    "- size of luggage boot\n",
    "- estimated safety\n",
    "\n",
    "The criteria are normalized between 0 and 1.\n",
    "\n",
    "Based on them the alternatives are assigned to four sorted classes, which are:\n",
    "1. unacceptable \n",
    "2. acceptable\n",
    "3. good\n",
    "4. very good\n",
    "\n",
    "However here they will be binerized between the second and third class into to:\n",
    "\n",
    "1. Bad\n",
    "2. Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/monodata/car evaluation.csv\",header=None)\n",
    "features = len(data.columns)-1\n",
    "crits = [\"price\",\"maintaince price\",\"doors\",\"capacity\",\"size of luggage\", \"safety\"]\n",
    "data.columns = crits+[\"class\"]#[f\"crit_{i}\" for i in range(features)]+[\"class\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"class\"]<=2,\"class\"] = 0\n",
    "data.loc[data[\"class\"]>=3,\"class\"] = 1\n",
    "data_classless = data.drop(columns=\"class\")\n",
    "classes = 2\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data(data_classless.to_numpy(),data[\"class\"].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the names and distribution of their values in different classes, it can be inferred that the price and maintaince price criterions are of cost types and the rest of the criterions are gain type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_class_counts(data[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is highly imbalanced, so there is a need for undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_combinations(data_classless)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of possible combinations of all values of the criterions and the number of alternatives is the same. Judging by that suspicious fact, it is safe to assume that the dataset is composed of all possible alternatives or that there is quite a number of repeated alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of performance and to avoid learning the most of the space of alternatives the first class needs to be heavily undersampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X,new_y = undersample(data_classless.to_numpy(),data[\"class\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data(new_X,new_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_rest, y_train, y_rest = train_test_split(new_X,new_y,test_size=0.40)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_rest,y_rest,test_size=0.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RankSVM method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate differencese between rows of different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_2d_differences(array:np.array):\n",
    "    difs = array[:,np.newaxis,:] - array \n",
    "    return difs.reshape(-1,array.shape[1])\n",
    "\n",
    "def calculate_1d_differences(vector:np.array):\n",
    "    difs = vector[:,np.newaxis] - vector\n",
    "    return difs.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_difs = calculate_2d_differences(X_train)\n",
    "X_test_difs = calculate_2d_differences(X_test)\n",
    "\n",
    "y_train_difs = calculate_1d_differences(y_train)\n",
    "y_test_difs = calculate_1d_differences(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_filtered = y_train_difs[y_train_difs != 0]\n",
    "y_test_filtered = y_test_difs[y_test_difs != 0]\n",
    "\n",
    "X_train_filtered = X_train_difs[y_train_difs != 0]\n",
    "X_test_filtered = X_test_difs[y_test_difs != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_svm = LinearSVC()#make_pipeline(StandardScaler(),LinearSVC())\n",
    "\n",
    "rank_svm.fit(X_train_filtered,y_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance on train set:\\n\")\n",
    "show_stats(rank_svm,X_train_filtered,y_train_filtered)\n",
    "print(\"\\nPerformance on test set:\\n\")\n",
    "show_stats(rank_svm,X_test_filtered,y_test_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN-UTADIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tensors.layers import MonotoneBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.9\n",
    "ideal_alt = [0,0,1,1,1,1]\n",
    "antiideal_alt = [1,1,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uta_model = create_ann_utadis_model(threshold,ideal_alt,antiideal_alt,classes,features,L=7)\n",
    "uta_model.build(input_shape=(None,features))\n",
    "uta_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train(uta_model,X_train,y_train,mean_regret,\n",
    "                val_data=(X_val,y_val),\n",
    "                batch=len(X_train),\n",
    "                epochs=20,\n",
    "                patience=5,\n",
    "                metrics=[UtilMetric(Accuracy()),UtilMetric(AUC(name=\"auc\")),UtilMetric(F1Score())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_monotone_blocks(uta_model.uta,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_criteria_weights(uta_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = create_nn_model(features)\n",
    "\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(nn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train(nn_model,X_train,y_train,\"binary_crossentropy\",val_data=(X_val,y_val),patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--bibtex \n",
    "\n",
    "@Article{Tehrani2011/08,\n",
    "  title={Choquistic Regression: Generalizing Logistic Regression using the Choquet Integral},\n",
    "  author={Ali Fallah Tehrani and Weiwei Cheng and Eyke Hüllermeier},\n",
    "  year={2011/08},\n",
    "  booktitle={Proceedings of the 7th conference of the European Society for Fuzzy Logic and Technology (EUSFLAT-11)},\n",
    "  pages={868-875},\n",
    "  issn={1951-6851},\n",
    "  isbn={978-90-78677-00-0},\n",
    "  url={https://doi.org/10.2991/eusflat.2011.86},\n",
    "  doi={10.2991/eusflat.2011.86},\n",
    "  publisher={Atlantis Press}\n",
    "}\n",
    "-->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
